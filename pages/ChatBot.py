import os
import pandas as pd
import streamlit as st
from langchain_google_genai import ChatGoogleGenerativeAI

if 'GOOGLE_API_KEY' not in os.environ:
    os.environ['GOOGLE_API_KEY'] = "AIzaSyBtL9pH7na1PF4Y-AxI51bxv83dCsS89nY"

llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.5)

transaction_path = "D:/OneDrive/Desktop/Awake Drive JSC/finance-tool/pages/chiphi.xlsx"
plan_path = "D:/OneDrive/Desktop/Awake Drive JSC/finance-tool/pages/plan.xlsx"

task_prompt_template = """
    B·∫°n l√† ChatBot AI t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng v·ªÅ c√°c d·ªØ li·ªáu t√†i ch√≠nh c·ªßa c√¥ng ty Awake Drive.
    C√¥ng ty c·ªï ph·∫ßn Awake Drive l√† c√¥ng ty cung c·∫•p s·∫£n ph·∫©m gi√∫p gi√°m s√°t v√† duy tr√¨ ƒë·ªô t·ªânh t√°o c·ªßa t√†i x·∫ø d·ª±a tr√™n c√¥ng ngh·ªá AI v√† c√¥ng ngh·ªá s√≥ng n√£o.
    Ph√¢n lo·∫°i xem ng∆∞·ªùi d√πng ƒëang mu·ªën th·ª±c hi·ªán nhi·ªám v·ª• g√¨ t·ª´ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng:
    {context}
    ####
    C√°c lo·∫°i nhi·ªám v·ª•:
    1. Nhi·ªám v·ª• li√™n quan ƒë·∫øn ghi ch√©p thu chi, ph√¢n t√≠ch thu chi (transactions)
    2. Nhi·ªám v·ª• li√™n quan ƒë·∫øn k·∫ø ho·∫°ch 6 th√°ng (plan)
    3. Nhi·ªám v·ª• li√™n quan ƒë·∫øn c·∫£ thu chi v√† k·∫ø ho·∫°ch 
    Y√™u c·∫ßu tr·∫£ v·ªÅ duy nh·∫•t 1 s·ªë th·ªÉ hi·ªán cho nhi·ªám v·ª•
"""

detailed_prompt_template = """
    B·∫°n l√† ChatBot AI t∆∞∆°ng t√°c v·ªõi ng∆∞·ªùi d√πng v·ªÅ c√°c d·ªØ li·ªáu t√†i ch√≠nh c·ªßa c√¥ng ty Awake Drive.
    C√¥ng ty c·ªï ph·∫ßn Awake Drive l√† c√¥ng ty cung c·∫•p s·∫£n ph·∫©m gi√∫p gi√°m s√°t v√† duy tr√¨ ƒë·ªô t·ªânh t√°o c·ªßa t√†i x·∫ø d·ª±a tr√™n c√¥ng ngh·ªá AI v√† c√¥ng ngh·ªá s√≥ng n√£o.
    D·ª±a v√†o file d·ªØ li·ªáu d∆∞·ªõi ƒë√¢y:
    {data}
    ####
    H√£y th·ª±c hi·ªán nhi·ªám v·ª• sau v√† ƒë∆∞a ra ƒë·ªÅ xu·∫•t h·ª£p l√Ω (n·∫øu c√≥) cho y√™u c·∫ßu:
    {question}
    N·∫øu l√† k·∫ø ho·∫°ch th√¨ n√≥ b·∫Øt ƒë·∫ßu t·ª´ th√°ng 12
"""

def load_excel_data(file_path):
    try:
        return pd.read_excel(file_path,engine='openpyxl')
    except FileNotFoundError:
        return pd.DataFrame()
data2 = load_excel_data(plan_path)
data1 = load_excel_data(transaction_path)
da = str(data1.to_json)
ta = str(data2.to_json)
data = da+ta
print("---")
print(data)
def create_task_prompt(context):
    return task_prompt_template.format(context=context)

def create_detailed_prompt(data, question):
    return detailed_prompt_template.format(data=data, question=question)

def get_response(prompt):
    response = llm.invoke(prompt).content.strip()
    return response


st.set_page_config(
    page_title="Financial AI Chatbot",
    page_icon="üìë",
    layout="wide"
)

st.title("üí¨ Financial AI Chatbot Assistant")
st.write(
    "Hello! I am your financial AI assistant, ready to help you analyze income and expense data, plan for the next 6 months, answer financial-related questions, and provide personalized recommendations to optimize your financial decisions based on your data."
)


if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

user_input = st.chat_input("üí¨ ƒê·∫∑t c√¢u h·ªèi v·ªÅ t√†i ch√≠nh t·∫°i ƒë√¢y...")

if user_input:

    st.session_state.chat_history.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    task_prompt = create_task_prompt(user_input)
    task_response = get_response(task_prompt)
    task_type = int(task_response) if task_response.isdigit() else None

    assistant_response = "Xin l·ªói, t√¥i kh√¥ng th·ªÉ hi·ªÉu y√™u c·∫ßu c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i."
    if task_type == 1:  # Nhi·ªám v·ª• "transactions"
        detailed_prompt = create_detailed_prompt(data=data1, question=user_input)
        assistant_response = get_response(detailed_prompt)

    elif task_type == 2:  # Nhi·ªám v·ª• "plan"
        detailed_prompt = create_detailed_prompt(data=data2, question=user_input)
        assistant_response = get_response(detailed_prompt)
    elif task_type == 3:
        detailed_prompt = create_detailed_prompt(data=data, question=user_input)
        assistant_response = get_response(detailed_prompt)

    with st.chat_message("assistant"):
        st.markdown(assistant_response)
    st.session_state.chat_history.append({"role": "assistant", "content": assistant_response})